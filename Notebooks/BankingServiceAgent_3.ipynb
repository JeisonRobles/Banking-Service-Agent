{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e87bfdc6662e4acc913e16e08d777794": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_973d1c9fba5d457387cfdecf33dcf898",
            "msg_id": "",
            "outputs": []
          }
        },
        "973d1c9fba5d457387cfdecf33dcf898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5896ef18040435c926ccc291af3ff0c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_23ad7f9365f24c19ba7092e22b886e3c",
            "msg_id": "",
            "outputs": []
          }
        },
        "23ad7f9365f24c19ba7092e22b886e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef67df1983684bc599e08e61f8acc5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "user: ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b8402ac5ff514effa337d919393f26e4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cd4c89abbda84e4481cb6da5a2913b00",
            "value": ""
          }
        },
        "b8402ac5ff514effa337d919393f26e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4c89abbda84e4481cb6da5a2913b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a2d00aacb1428197e7fae44d969d83": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_129f96608099472492c956ecb676fd70",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p style='padding: 5px;'><b style='padding-left: 12px;'>assistant:</b> All documents were processed. I'm ready! </p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p style='padding: 5px;'><b style='padding-left: 45px;'>user:</b> I need to check my products. My user is CUST-2002 </p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p style='padding: 5px;'><b style='padding-left: 12px;'>assistant:</b> {\"customer_id\":\"CUST-2002\"}<commentary to=functions.get_customer_products å½©ç¥žäº‰éœ¸å®˜æ–¹ä¸‹è½½json </p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p style='padding: 5px;'><b style='padding-left: 45px;'>user:</b>  I need to check my products. My user is CUST-2002 </p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p style='padding: 5px;'><b style='padding-left: 12px;'>assistant:</b> No get_customer_products tool available.<html>\n <body>\n <p>Hi Diego Hernandez, I can help you check your products for user <strong>CUST-2002</strong>.</p>\n <p><strong>To pull up your product list</strong>, Iâ€™ll need one quick confirmation for security:</p>\n <ul>\n <li>Are you logged into your online banking right now, or would you like me to guide you to where you can view your products?</li>\n </ul>\n\n <p><strong>In the meantime, hereâ€™s how to check them yourself:</strong></p>\n <ol>\n <li>Sign in to Online Banking / Mobile App</li>\n <li>Go to <strong>Accounts</strong> or <strong>Products</strong></li>\n <li>You should see items like checking, savings, credit cards, and loans listed there</li>\n </ol>\n\n <p>If you tell me whether youâ€™re using the <strong>mobile app</strong> or the <strong>website</strong>, Iâ€™ll give exact steps for that option.</p>\n </body>\n</html> </p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p style='padding: 5px;'><b style='padding-left: 45px;'>user:</b> Bring the full policy about credit cards </p>"
                },
                "metadata": {}
              }
            ]
          }
        },
        "129f96608099472492c956ecb676fd70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d43c361fb354c67b88f34c938882c83": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_75a68c78fc8a479896dd31892a630844",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p style='padding: 5px;'><b style='padding-left: 12px;'>assistant:</b> <html>\n <body>\n <p>I canâ€™t provide the <strong>full, verbatim internal credit card policy</strong>. However, I can explain the credit card rules and how they generally work in plain language.</p>\n\n <h3>Credit card basics (easy overview)</h3>\n <ul>\n <li><strong>Credit limit:</strong> the maximum amount you can borrow on the card at one time.</li>\n <li><strong>Balance:</strong> what you currently owe.</li>\n <li><strong>Available credit:</strong> usually <em>credit limit âˆ’ current balance</em> (pending transactions can affect this).</li>\n <li><strong>APR (interest rate):</strong> the yearly rate used to calculate interest on carried balances.</li>\n </ul>\n\n <h3>Payments &amp; minimum payment</h3>\n <ul>\n <li><strong>Minimum payment:</strong> the smallest amount you must pay by the due date to keep the account current.</li>\n <li>Paying only the minimum can lead to <strong>more interest over time</strong> and a longer payoff period.</li>\n <li>Paying more than the minimum (or paying in full) typically reduces or avoids interest on new purchases, depending on your billing cycle rules.</li>\n </ul>\n\n <h3>Interest &amp; fees (general)</h3>\n <ul>\n <li>If you <strong>carry a balance</strong> past the due date, interest is generally charged based on the APR and your daily balance.</li>\n <li>Common fee types can include <strong>late payment</strong> or <strong>returned payment</strong> fees (exact amounts depend on the card agreement).</li>\n <li>I can explain how these work conceptually, but I wonâ€™t quote internal-only details or calculate exact charges without official statement data.</li>\n </ul>\n\n <h3>What I can and canâ€™t do for credit cards</h3>\n <ul>\n <li><strong>I can:</strong> explain terms (APR, limits, utilization), how payments affect balances, and guide you on where to find details in your statements.</li>\n <li><strong>I canâ€™t:</strong> share internal policy text, reveal security/fraud thresholds, or perform account actions like changing limits, closing cards, or making payments/transfers.</li>\n </ul>\n\n <h3>If you want the official wording</h3>\n <p>The best source is your cardâ€™s <strong>Cardholder Agreement</strong> and your <strong>monthly statement</strong>. If you tell me whether youâ€™re using the <strong>mobile app</strong> or <strong>website</strong>, I can guide you to where those documents usually are.</p>\n\n <p>What exactly do you want from the policyâ€”<strong>fees</strong>, <strong>interest/APR</strong>, <strong>minimum payment</strong>, <strong>disputes/chargebacks</strong>, or <strong>credit limit changes</strong>?</p>\n </body>\n</html> </p>"
                },
                "metadata": {}
              }
            ]
          }
        },
        "75a68c78fc8a479896dd31892a630844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae756d5ee90143fca83f7c9aa3d2ebe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "user: ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0a4b063ae9204a89b226598a609afd0b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5a625480a2a64c24aa089c5920c89864",
            "value": ""
          }
        },
        "0a4b063ae9204a89b226598a609afd0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a625480a2a64c24aa089c5920c89864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#. ðŸ¦ Banking Service Agent ðŸ’µ\n",
        "\n",
        "**What's about:** Banking Customer Service Agent with RAG and Sqlite toolsfor products and policy related questions.\n",
        "\n",
        "Dev by Jeison Robles."
      ],
      "metadata": {
        "id": "omYHRITN6jFE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SsBIjXNxtnul"
      },
      "outputs": [],
      "source": [
        "%pip install -q openai qdrant-client docling fastembed jupyter-chat-widget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jupyter_chat_widget import ChatUI\n",
        "from time import sleep\n",
        "\n",
        "chat = ChatUI()\n",
        "\n",
        "def answers(text):\n",
        "  chat.rewrite(\"Thinking...\")\n",
        "  sleep(3)\n",
        "  chat.rewrite(\"\")\n",
        "  chat.append(\"Hello \"+ text)\n",
        "\n",
        "chat.connect(answers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e87bfdc6662e4acc913e16e08d777794",
            "973d1c9fba5d457387cfdecf33dcf898",
            "e5896ef18040435c926ccc291af3ff0c",
            "23ad7f9365f24c19ba7092e22b886e3c",
            "ef67df1983684bc599e08e61f8acc5cf",
            "b8402ac5ff514effa337d919393f26e4",
            "cd4c89abbda84e4481cb6da5a2913b00"
          ]
        },
        "id": "9kVEIYNAtzbr",
        "outputId": "ad58b5a0-6655-41df-85ae-dd01562d2235"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e87bfdc6662e4acc913e16e08d777794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5896ef18040435c926ccc291af3ff0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='user: ')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef67df1983684bc599e08e61f8acc5cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep Functions"
      ],
      "metadata": {
        "id": "6n1j7lUvyqqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "def get_oai_client():\n",
        "    \"\"\"\n",
        "        Creates the OpenAI client.\n",
        "    \"\"\"\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    client = openai.OpenAI()\n",
        "    messages = [{\"role\": \"system\",\n",
        "                 \"content\": \"\"\"You are a helpful banking assistant,\n",
        "                  you must paraphrase the policy undertand customer questions\n",
        "                   and provide easy to understand, Never can provide the explicit policy. Output in HTML.\"\"\"}]\n",
        "    return client, messages\n",
        "\n",
        "\n",
        "def query_llm(ui, client, messages):\n",
        "    \"\"\"\n",
        "        Query the LLM and returns a stream handle to the response.\n",
        "    \"\"\"\n",
        "    ui.rewrite(\"[Generating]\")\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",  # Or another suitable model\n",
        "        messages=messages, # Use the message history\n",
        "        stream=True, # Enable streaming\n",
        "    )\n",
        "    return stream\n",
        "\n",
        "\n",
        "def display_response(ui, stream):\n",
        "    \"\"\"\n",
        "        Display the LLM's response in the UI one token at a time.\n",
        "    \"\"\"\n",
        "    ui.rewrite(\"\")\n",
        "    complete_response = \"\"\n",
        "    for chunk in stream:\n",
        "        if (content := chunk.choices[0].delta.content) and content.strip():\n",
        "            complete_response += content\n",
        "            ui.append(content)\n",
        "    return complete_response\n"
      ],
      "metadata": {
        "id": "-HV6XF_vyO7e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Policy"
      ],
      "metadata": {
        "id": "dvARy7m3ygNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "urls_and_filenames = [\n",
        "    (\n",
        "        \"https://raw.githubusercontent.com/JeisonRobles/Banking-Service-Agent/main/Bank_Policy_1\",\n",
        "        \"Bank_Policy_1.md\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "os.makedirs(\"documents\", exist_ok=True)\n",
        "\n",
        "for url, filename in urls_and_filenames:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(os.path.join(\"documents\", filename), \"wb\") as f:\n",
        "        f.write(response.content)"
      ],
      "metadata": {
        "id": "zlogiPXUv8FV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documents processing"
      ],
      "metadata": {
        "id": "7bKvhzHKyluX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "from docling.chunking import HybridChunker\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.document_converter import DocumentConverter\n",
        "from uuid import uuid4\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "\n",
        "def ingest_documents(ui, paths):\n",
        "    print(\"Ingesting documents...\")\n",
        "    print(paths)\n",
        "    # Prepare the vectordb and embedder\n",
        "    vdb = QdrantClient(location=\":memory:\")\n",
        "    dense_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    vdb.set_model(dense_model)\n",
        "    collection_name = \"documents\"\n",
        "    vdb.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config=vdb.get_fastembed_vector_params(),\n",
        "    )\n",
        "    points = []\n",
        "    for path in paths:\n",
        "        print(path)\n",
        "\n",
        "    print(f\"processing path: {paths}\")\n",
        "\n",
        "    ui.rewrite(f\"[Parsing {paths}...]\")\n",
        "\n",
        "\n",
        "    for path in paths:\n",
        "\n",
        "        print(f\"processing path: {path}\")\n",
        "\n",
        "        ui.rewrite(f\"[Parsing {path}...]\")\n",
        "\n",
        "        # Parse the document with docling\n",
        "        doc = DocumentConverter().convert(source=path).document\n",
        "\n",
        "        # Chunk the document\n",
        "        chunker = HybridChunker()\n",
        "        chunk_iter = chunker.chunk(dl_doc=doc)\n",
        "\n",
        "        # Enrich the chunks and build Qdrant points\n",
        "        for chunk in chunk_iter:\n",
        "            enriched_text = chunker.contextualize(chunk=chunk)\n",
        "            meta = chunk.meta.export_json_dict()\n",
        "            points.append(\n",
        "                models.PointStruct(\n",
        "                    id=uuid4().hex,\n",
        "                    payload=meta | {\"document\": enriched_text},\n",
        "                    vector={\n",
        "                        # FastEmbed uses named vector fields derived from the model names\n",
        "                        vdb.get_vector_field_name(): models.Document(text=enriched_text, model=dense_model),\n",
        "                    },\n",
        "                )\n",
        "            )\n",
        "    # Upload (embeddings happen internally because we used models.Document)\n",
        "    vdb.upload_points(collection_name=collection_name, points=points, batch_size=64, wait=True)\n",
        "    ui.rewrite(f\"All documents were processed. I'm ready!\")\n",
        "    return vdb\n",
        "\n",
        "def add_context(ui, vdb, query):\n",
        "    \"\"\"\n",
        "        Queries the vector database for relevant context snippets\n",
        "        and adds them to the LLM's context.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Adding context...\")\n",
        "    ui.rewrite(\"[Searching]\")\n",
        "    samples = vdb.query(\n",
        "        collection_name=\"documents\",\n",
        "        query_text=query,\n",
        "        limit=10,\n",
        "    )\n",
        "    ui.rewrite(f\"[Found {len(samples)} relevant snippets]\")\n",
        "    sleep(1)\n",
        "    return {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Relevant snippets from the document: {'\\n\\n'.join(s.document for s in samples)}\"\n",
        "    }"
      ],
      "metadata": {
        "id": "QOjJdl1_xrQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d2858f-55fa-49ce-8433-6d129417a7af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’¾ SQL Local DB\n",
        "\n",
        "Lets implement an small SQLite db for customers patterns\n"
      ],
      "metadata": {
        "id": "E8IcihDkIDxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from pathlib import Path\n",
        "\n",
        "DB_PATH = Path(\"bank_demo.sqlite\")\n",
        "\n",
        "def init_customer_db(db_path: Path= DB_PATH):\n",
        "  \"\"\"Creates a tiny local SQLite DB with customers.\"\"\"\n",
        "  conn = sqlite3.connect(str(db_path))\n",
        "  cur = conn.cursor()\n",
        "  cur.execute(\"\"\"\n",
        "  CREATE TABLE IF NOT EXISTS customers(\n",
        "    customer_id TEXT PRIMARY KEY,\n",
        "    full_name TEXT NOT NULL\n",
        "  )\n",
        "  \"\"\")\n",
        "\n",
        "  #Seed demo rows (idemponent)\n",
        "  cur.executemany(\n",
        "      \"INSERT OR IGNORE INTO customers (customer_id, full_name) VALUES (?, ?)\",\n",
        "      [\n",
        "          (\"CUST-1001\", \"Alicia Mora\"),\n",
        "          (\"CUST-2002\", \"Diego Hernandez\"),\n",
        "          (\"CUST-3OO3\", \"Maria Jose Vargas\"),\n",
        "      ]\n",
        "  )\n",
        "  conn.commit()\n",
        "  conn.close()\n",
        "  return str(db_path.resolve())\n",
        "\n",
        "DB_RESOLVED = init_customer_db()\n",
        "print(f\"SQLite demo DB ready at: {DB_RESOLVED}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiKnDRm1IYNL",
        "outputId": "fee733b7-ed40-4121-af0c-3536601abe79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SQLite demo DB ready at: /content/bank_demo.sqlite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Tool: lookup customer name (used only for \"my products\"/personal info requests) ---\n",
        "import sqlite3\n",
        "from typing import Dict, Any\n",
        "import json\n",
        "\n",
        "def get_customer_name(customer_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Return customer name for greeting; no products yet.\"\"\"\n",
        "    conn = sqlite3.connect(str(DB_PATH))\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"SELECT full_name FROM customers WHERE customer_id = ?\", (customer_id,))\n",
        "    row = cur.fetchone()\n",
        "    conn.close()\n",
        "    if not row:\n",
        "        return {\"found\": False, \"customer_id\": customer_id, \"full_name\": None}\n",
        "    return {\"found\": True, \"customer_id\": customer_id, \"full_name\": row[0]}\n",
        "\n",
        "# Tool implementations registry (keep/extend your existing one if present)\n",
        "try:\n",
        "    tool_implementations\n",
        "except NameError:\n",
        "    tool_implementations = {}\n",
        "\n",
        "tool_implementations[\"get_customer_name\"] = lambda ui, vdb, customer_id: {\n",
        "    \"role\": \"tool\",\n",
        "    \"name\": \"get_customer_name\",\n",
        "    \"content\": json.dumps(get_customer_name(customer_id), ensure_ascii=False),\n",
        "}\n"
      ],
      "metadata": {
        "id": "Zl3hJH06Liwu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "# Retrieval as a tool"
      ],
      "metadata": {
        "id": "n802_IcJ85GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def _invoke_tool(ui, vdb, tool_call):\n",
        "    tool_name = tool_call.function.name\n",
        "    ui.rewrite(f\"Calling tool {tool_name}\")\n",
        "\n",
        "    tool_args = json.loads(tool_call.function.arguments or \"{}\")\n",
        "\n",
        "    tool_impl = tool_implementations[tool_name]\n",
        "    output = tool_impl(ui, vdb, **tool_args)  # returns {\"role\":\"tool\",\"name\":...,\"content\":...}\n",
        "\n",
        "    # IMPORTANT: tool message MUST include tool_call_id\n",
        "    tool_msg = {\n",
        "        \"role\": \"tool\",\n",
        "        \"tool_call_id\": tool_call.id,\n",
        "        \"content\": output[\"content\"],\n",
        "    }\n",
        "    return tool_msg\n",
        "\n",
        "\n",
        "def query_llm_with_tools(ui, client, vdb, messages, tools):\n",
        "    \"\"\"\n",
        "    Minimal, correct tool loop:\n",
        "    - First call (non-stream) to see if model wants tools\n",
        "    - If tool_calls: append assistant tool_calls -> append tool result with tool_call_id -> call again (stream) for final answer\n",
        "    - If no tool_calls: just stream answer\n",
        "    \"\"\"\n",
        "    ui.rewrite(\"[Generating]\")\n",
        "\n",
        "    # 1) NON-STREAM call to decide whether tools are needed\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        stream=False,\n",
        "    )\n",
        "    assistant_msg = resp.choices[0].message\n",
        "\n",
        "    tool_calls = getattr(assistant_msg, \"tool_calls\", None)\n",
        "\n",
        "    # 2) If no tools requested -> stream normal assistant content\n",
        "    if not tool_calls:\n",
        "        stream = client.chat.completions.create(\n",
        "            model=\"gpt-5.2\",\n",
        "            messages=messages,\n",
        "            stream=True,\n",
        "        )\n",
        "        return stream\n",
        "\n",
        "    # 3) Tools requested -> append assistant message WITH tool_calls (required)\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": assistant_msg.content,\n",
        "        \"tool_calls\": [tc.model_dump() for tc in tool_calls],\n",
        "    })\n",
        "\n",
        "    # 4) Execute each tool call and append tool results WITH tool_call_id\n",
        "    for tc in tool_calls:\n",
        "        tool_msg = _invoke_tool(ui, vdb, tc)\n",
        "        messages.append(tool_msg)\n",
        "\n",
        "    # 5) Call model again to produce final answer (streaming is OK here)\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=messages,\n",
        "        stream=True,\n",
        "    )\n",
        "    return stream"
      ],
      "metadata": {
        "id": "Dhq_JOFG8AK3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep existing tools and add/override entries\n",
        "tool_implementations.update({\n",
        "    \"search\": add_context,\n",
        "    \"get_customer_name\": lambda ui, vdb, customer_id: {\n",
        "        \"role\": \"tool\",\n",
        "        \"name\": \"get_customer_name\",\n",
        "        \"content\": json.dumps(get_customer_name(customer_id), ensure_ascii=False),\n",
        "    }\n",
        "})\n",
        "\n",
        "search = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"search\",\n",
        "        \"description\": \"Use this tool when the user is asking you something you don't know. You should use this tool very often and you can call it many times in a row if necessary.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"query\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\":\n",
        "                        \"The query to retrieve the information from the document store using pure embedding similarity search\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"query\"],\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "get_customer_name_tool = {\n",
        "  \"type\": \"function\",\n",
        "  \"function\": {\n",
        "    \"name\": \"get_customer_name\",\n",
        "    \"description\": \"Look up the customer's full name by customer_id for a personalized greeting. Use only when the user asks about their own products/accounts and provides a customer_id.\",\n",
        "    \"parameters\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"customer_id\": {\n",
        "          \"type\": \"string\",\n",
        "          \"description\": \"Customer ID in format CUST-#### (e.g., CUST-2002).\"\n",
        "        }\n",
        "      },\n",
        "      \"required\": [\"customer_id\"]\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "def retrieval_as_tool(paths):\n",
        "    ui = ChatUI()\n",
        "    vdb = ingest_documents(ui, paths)\n",
        "    client, messages = get_oai_client()\n",
        "\n",
        "    def _retrieval_as_tool(query):\n",
        "        messages.append({\"role\": \"user\", \"content\": query})\n",
        "        #stream = query_llm_with_tools(ui, client, vdb, messages, [search])\n",
        "        stream = query_llm_with_tools(ui, client, vdb, messages, [search, get_customer_name_tool]) ## Calling the model with both tools\n",
        "        response = display_response(ui, stream)\n",
        "        messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    ui.connect(lambda query: _retrieval_as_tool(query))"
      ],
      "metadata": {
        "id": "fChnRvbH9AN2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_as_tool([\"/content/documents/Bank_Policy_1.md\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "06a2d00aacb1428197e7fae44d969d83",
            "129f96608099472492c956ecb676fd70",
            "8d43c361fb354c67b88f34c938882c83",
            "75a68c78fc8a479896dd31892a630844",
            "ae756d5ee90143fca83f7c9aa3d2ebe0",
            "0a4b063ae9204a89b226598a609afd0b",
            "5a625480a2a64c24aa089c5920c89864"
          ]
        },
        "id": "i7eE9mun9Sad",
        "outputId": "49d40239-f3c6-4e53-f558-3d3555370804"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06a2d00aacb1428197e7fae44d969d83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d43c361fb354c67b88f34c938882c83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='user: ')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae756d5ee90143fca83f7c9aa3d2ebe0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingesting documents...\n",
            "['/content/documents/Bank_Policy_1.md']\n",
            "/content/documents/Bank_Policy_1.md\n",
            "processing path: ['/content/documents/Bank_Policy_1.md']\n",
            "processing path: /content/documents/Bank_Policy_1.md\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding context...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/qdrant_client/common/client_warnings.py:7: UserWarning: `query` method has been deprecated and will be removed in 1.17. Instead, inference can be done internally within regular methods like `query_points` by wrapping data into `models.Document` or `models.Image`.\n",
            "  warnings.warn(message, category, stacklevel=stacklevel)\n"
          ]
        }
      ]
    }
  ]
}